/**
 * Generated by Scrooge
 *   version: 4.16.0-SNAPSHOT
 *   rev: eb110c820bcd2734b26023f24d636bf6d37511b3
 *   built at: 20170607-185808
 */
package parquet.format

import com.twitter.io.Buf
import com.twitter.scrooge.{
  HasThriftStructCodec3,
  LazyTProtocol,
  TFieldBlob,
  ThriftException,
  ThriftStruct,
  ThriftStructCodec3,
  ThriftStructFieldInfo,
  ThriftStructMetaData,
  ThriftUtil
}
import org.apache.thrift.protocol._
import org.apache.thrift.transport.{TMemoryBuffer, TTransport, TIOStreamTransport}
import java.io.ByteArrayInputStream
import java.nio.ByteBuffer
import java.util.Arrays
import java.util.concurrent.atomic.AtomicInteger
import scala.collection.immutable.{Map => immutable$Map}
import scala.collection.mutable.Builder
import scala.collection.mutable.{
  ArrayBuffer => mutable$ArrayBuffer, Buffer => mutable$Buffer,
  HashMap => mutable$HashMap, HashSet => mutable$HashSet}
import scala.collection.{Map, Set}


object PageHeader extends ThriftStructCodec3[PageHeader] {
  val NoPassthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty[Short, TFieldBlob]
  val Struct = new TStruct("PageHeader")
  val TypeField = new TField("type", TType.ENUM, 1)
  val TypeFieldI32 = new TField("type", TType.I32, 1)
  val TypeFieldManifest = implicitly[Manifest[parquet.format.PageType]]
  val UncompressedPageSizeField = new TField("uncompressed_page_size", TType.I32, 2)
  val UncompressedPageSizeFieldManifest = implicitly[Manifest[Int]]
  val CompressedPageSizeField = new TField("compressed_page_size", TType.I32, 3)
  val CompressedPageSizeFieldManifest = implicitly[Manifest[Int]]
  val CrcField = new TField("crc", TType.I32, 4)
  val CrcFieldManifest = implicitly[Manifest[Int]]
  val DataPageHeaderField = new TField("data_page_header", TType.STRUCT, 5)
  val DataPageHeaderFieldManifest = implicitly[Manifest[parquet.format.DataPageHeader]]
  val DictionaryPageHeaderField = new TField("dictionary_page_header", TType.STRUCT, 6)
  val DictionaryPageHeaderFieldManifest = implicitly[Manifest[parquet.format.DictionaryPageHeader]]
  val DataPageHeaderV2Field = new TField("data_page_header_v2", TType.STRUCT, 7)
  val DataPageHeaderV2FieldManifest = implicitly[Manifest[parquet.format.DataPageHeaderV2]]

  /**
   * Field information in declaration order.
   */
  lazy val fieldInfos: scala.List[ThriftStructFieldInfo] = scala.List[ThriftStructFieldInfo](
    new ThriftStructFieldInfo(
      TypeField,
      false,
      true,
      TypeFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      UncompressedPageSizeField,
      false,
      true,
      UncompressedPageSizeFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      CompressedPageSizeField,
      false,
      true,
      CompressedPageSizeFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      CrcField,
      true,
      false,
      CrcFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      DataPageHeaderField,
      true,
      false,
      DataPageHeaderFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      DictionaryPageHeaderField,
      true,
      false,
      DictionaryPageHeaderFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      DataPageHeaderV2Field,
      true,
      false,
      DataPageHeaderV2FieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    )
  )

  lazy val structAnnotations: immutable$Map[String, String] =
    immutable$Map.empty[String, String]

  /**
   * Checks that all required fields are non-null.
   */
  def validate(_item: PageHeader): Unit = {
    if (_item.`type` == null) throw new TProtocolException("Required field `type` cannot be null")
  }

  def withoutPassthroughFields(original: PageHeader): PageHeader =
    new Immutable(
      `type` =
        {
          val field = original.`type`
          field
        },
      uncompressedPageSize =
        {
          val field = original.uncompressedPageSize
          field
        },
      compressedPageSize =
        {
          val field = original.compressedPageSize
          field
        },
      crc =
        {
          val field = original.crc
          field.map { field =>
            field
          }
        },
      dataPageHeader =
        {
          val field = original.dataPageHeader
          field.map { field =>
            parquet.format.DataPageHeader.withoutPassthroughFields(field)
          }
        },
      dictionaryPageHeader =
        {
          val field = original.dictionaryPageHeader
          field.map { field =>
            parquet.format.DictionaryPageHeader.withoutPassthroughFields(field)
          }
        },
      dataPageHeaderV2 =
        {
          val field = original.dataPageHeaderV2
          field.map { field =>
            parquet.format.DataPageHeaderV2.withoutPassthroughFields(field)
          }
        }
    )

  override def encode(_item: PageHeader, _oproto: TProtocol): Unit = {
    _item.write(_oproto)
  }


  private[this] def lazyDecode(_iprot: LazyTProtocol): PageHeader = {

    var `type`: parquet.format.PageType = null
    var _got_type = false
    var uncompressedPageSize: Int = 0
    var _got_uncompressedPageSize = false
    var compressedPageSize: Int = 0
    var _got_compressedPageSize = false
    var crcOffset: Int = -1
    var dataPageHeader: Option[parquet.format.DataPageHeader] = None
    var dictionaryPageHeader: Option[parquet.format.DictionaryPageHeader] = None
    var dataPageHeaderV2: Option[parquet.format.DataPageHeaderV2] = None

    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false
    val _start_offset = _iprot.offset

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.I32 | TType.ENUM =>
    
                `type` = readTypeValue(_iprot)
                _got_type = true
              case _actualType =>
                val _expectedType = TType.ENUM
                throw new TProtocolException(
                  "Received wrong type for field '`type`' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.I32 =>
    
                uncompressedPageSize = readUncompressedPageSizeValue(_iprot)
                _got_uncompressedPageSize = true
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'uncompressedPageSize' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.I32 =>
    
                compressedPageSize = readCompressedPageSizeValue(_iprot)
                _got_compressedPageSize = true
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'compressedPageSize' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.I32 =>
                crcOffset = _iprot.offsetSkipI32
    
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'crc' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                dataPageHeader = Some(readDataPageHeaderValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'dataPageHeader' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 6 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                dictionaryPageHeader = Some(readDictionaryPageHeaderValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'dictionaryPageHeader' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 7 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                dataPageHeaderV2 = Some(readDataPageHeaderV2Value(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'dataPageHeaderV2' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    if (!_got_type) throw new TProtocolException("Required field '`type`' was not found in serialized data for struct PageHeader")
    if (!_got_uncompressedPageSize) throw new TProtocolException("Required field 'uncompressedPageSize' was not found in serialized data for struct PageHeader")
    if (!_got_compressedPageSize) throw new TProtocolException("Required field 'compressedPageSize' was not found in serialized data for struct PageHeader")
    new LazyImmutable(
      _iprot,
      _iprot.buffer,
      _start_offset,
      _iprot.offset,
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crcOffset,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  override def decode(_iprot: TProtocol): PageHeader =
    _iprot match {
      case i: LazyTProtocol => lazyDecode(i)
      case i => eagerDecode(i)
    }

  private[format] def eagerDecode(_iprot: TProtocol): PageHeader = {
    var `type`: parquet.format.PageType = null
    var _got_type = false
    var uncompressedPageSize: Int = 0
    var _got_uncompressedPageSize = false
    var compressedPageSize: Int = 0
    var _got_compressedPageSize = false
    var crc: _root_.scala.Option[Int] = _root_.scala.None
    var dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader] = _root_.scala.None
    var dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader] = _root_.scala.None
    var dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2] = _root_.scala.None
    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.I32 | TType.ENUM =>
                `type` = readTypeValue(_iprot)
                _got_type = true
              case _actualType =>
                val _expectedType = TType.ENUM
                throw new TProtocolException(
                  "Received wrong type for field '`type`' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.I32 =>
                uncompressedPageSize = readUncompressedPageSizeValue(_iprot)
                _got_uncompressedPageSize = true
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'uncompressedPageSize' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.I32 =>
                compressedPageSize = readCompressedPageSizeValue(_iprot)
                _got_compressedPageSize = true
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'compressedPageSize' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.I32 =>
                crc = _root_.scala.Some(readCrcValue(_iprot))
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'crc' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.STRUCT =>
                dataPageHeader = _root_.scala.Some(readDataPageHeaderValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'dataPageHeader' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 6 =>
            _field.`type` match {
              case TType.STRUCT =>
                dictionaryPageHeader = _root_.scala.Some(readDictionaryPageHeaderValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'dictionaryPageHeader' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 7 =>
            _field.`type` match {
              case TType.STRUCT =>
                dataPageHeaderV2 = _root_.scala.Some(readDataPageHeaderV2Value(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'dataPageHeaderV2' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    if (!_got_type) throw new TProtocolException("Required field '`type`' was not found in serialized data for struct PageHeader")
    if (!_got_uncompressedPageSize) throw new TProtocolException("Required field 'uncompressedPageSize' was not found in serialized data for struct PageHeader")
    if (!_got_compressedPageSize) throw new TProtocolException("Required field 'compressedPageSize' was not found in serialized data for struct PageHeader")
    new Immutable(
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crc,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  def apply(
    `type`: parquet.format.PageType,
    uncompressedPageSize: Int,
    compressedPageSize: Int,
    crc: _root_.scala.Option[Int] = _root_.scala.None,
    dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader] = _root_.scala.None,
    dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader] = _root_.scala.None,
    dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2] = _root_.scala.None
  ): PageHeader =
    new Immutable(
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crc,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2
    )

  def unapply(_item: PageHeader): _root_.scala.Option[_root_.scala.Tuple7[parquet.format.PageType, Int, Int, Option[Int], Option[parquet.format.DataPageHeader], Option[parquet.format.DictionaryPageHeader], Option[parquet.format.DataPageHeaderV2]]] = _root_.scala.Some(_item.toTuple)


  @inline private[format] def readTypeValue(_iprot: TProtocol): parquet.format.PageType = {
    parquet.format.PageType.getOrUnknown(_iprot.readI32())
  }

  @inline private def writeTypeField(type_item: parquet.format.PageType, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(TypeFieldI32)
    writeTypeValue(type_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeTypeValue(type_item: parquet.format.PageType, _oprot: TProtocol): Unit = {
    _oprot.writeI32(type_item.value)
  }

  @inline private[format] def readUncompressedPageSizeValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeUncompressedPageSizeField(uncompressedPageSize_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(UncompressedPageSizeField)
    writeUncompressedPageSizeValue(uncompressedPageSize_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeUncompressedPageSizeValue(uncompressedPageSize_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(uncompressedPageSize_item)
  }

  @inline private[format] def readCompressedPageSizeValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeCompressedPageSizeField(compressedPageSize_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(CompressedPageSizeField)
    writeCompressedPageSizeValue(compressedPageSize_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeCompressedPageSizeValue(compressedPageSize_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(compressedPageSize_item)
  }

  @inline private[format] def readCrcValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeCrcField(crc_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(CrcField)
    writeCrcValue(crc_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeCrcValue(crc_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(crc_item)
  }

  @inline private[format] def readDataPageHeaderValue(_iprot: TProtocol): parquet.format.DataPageHeader = {
    parquet.format.DataPageHeader.decode(_iprot)
  }

  @inline private def writeDataPageHeaderField(dataPageHeader_item: parquet.format.DataPageHeader, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(DataPageHeaderField)
    writeDataPageHeaderValue(dataPageHeader_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeDataPageHeaderValue(dataPageHeader_item: parquet.format.DataPageHeader, _oprot: TProtocol): Unit = {
    dataPageHeader_item.write(_oprot)
  }

  @inline private[format] def readDictionaryPageHeaderValue(_iprot: TProtocol): parquet.format.DictionaryPageHeader = {
    parquet.format.DictionaryPageHeader.decode(_iprot)
  }

  @inline private def writeDictionaryPageHeaderField(dictionaryPageHeader_item: parquet.format.DictionaryPageHeader, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(DictionaryPageHeaderField)
    writeDictionaryPageHeaderValue(dictionaryPageHeader_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeDictionaryPageHeaderValue(dictionaryPageHeader_item: parquet.format.DictionaryPageHeader, _oprot: TProtocol): Unit = {
    dictionaryPageHeader_item.write(_oprot)
  }

  @inline private[format] def readDataPageHeaderV2Value(_iprot: TProtocol): parquet.format.DataPageHeaderV2 = {
    parquet.format.DataPageHeaderV2.decode(_iprot)
  }

  @inline private def writeDataPageHeaderV2Field(dataPageHeaderV2_item: parquet.format.DataPageHeaderV2, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(DataPageHeaderV2Field)
    writeDataPageHeaderV2Value(dataPageHeaderV2_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeDataPageHeaderV2Value(dataPageHeaderV2_item: parquet.format.DataPageHeaderV2, _oprot: TProtocol): Unit = {
    dataPageHeaderV2_item.write(_oprot)
  }


  object Immutable extends ThriftStructCodec3[PageHeader] {
    override def encode(_item: PageHeader, _oproto: TProtocol): Unit = { _item.write(_oproto) }
    override def decode(_iprot: TProtocol): PageHeader = PageHeader.decode(_iprot)
    override lazy val metaData: ThriftStructMetaData[PageHeader] = PageHeader.metaData
  }

  /**
   * The default read-only implementation of PageHeader.  You typically should not need to
   * directly reference this class; instead, use the PageHeader.apply method to construct
   * new instances.
   */
  class Immutable(
      val `type`: parquet.format.PageType,
      val uncompressedPageSize: Int,
      val compressedPageSize: Int,
      val crc: _root_.scala.Option[Int],
      val dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader],
      val dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader],
      val dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2],
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends PageHeader {
    def this(
      `type`: parquet.format.PageType,
      uncompressedPageSize: Int,
      compressedPageSize: Int,
      crc: _root_.scala.Option[Int] = _root_.scala.None,
      dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader] = _root_.scala.None,
      dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader] = _root_.scala.None,
      dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2] = _root_.scala.None
    ) = this(
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crc,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2,
      Map.empty
    )
  }

  /**
   * This is another Immutable, this however keeps strings as lazy values that are lazily decoded from the backing
   * array byte on read.
   */
  private[this] class LazyImmutable(
      _proto: LazyTProtocol,
      _buf: Array[Byte],
      _start_offset: Int,
      _end_offset: Int,
      val `type`: parquet.format.PageType,
      val uncompressedPageSize: Int,
      val compressedPageSize: Int,
      crcOffset: Int,
      val dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader],
      val dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader],
      val dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2],
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends PageHeader {

    override def write(_oprot: TProtocol): Unit = {
      _oprot match {
        case i: LazyTProtocol => i.writeRaw(_buf, _start_offset, _end_offset - _start_offset)
        case _ => super.write(_oprot)
      }
    }

    lazy val crc: _root_.scala.Option[Int] =
      if (crcOffset == -1)
        None
      else {
        Some(_proto.decodeI32(_buf, crcOffset))
      }

    /**
     * Override the super hash code to make it a lazy val rather than def.
     *
     * Calculating the hash code can be expensive, caching it where possible
     * can provide significant performance wins. (Key in a hash map for instance)
     * Usually not safe since the normal constructor will accept a mutable map or
     * set as an arg
     * Here however we control how the class is generated from serialized data.
     * With the class private and the contract that we throw away our mutable references
     * having the hash code lazy here is safe.
     */
    override lazy val hashCode = super.hashCode
  }

  /**
   * This Proxy trait allows you to extend the PageHeader trait with additional state or
   * behavior and implement the read-only methods from PageHeader using an underlying
   * instance.
   */
  trait Proxy extends PageHeader {
    protected def _underlying_PageHeader: PageHeader
    override def `type`: parquet.format.PageType = _underlying_PageHeader.`type`
    override def uncompressedPageSize: Int = _underlying_PageHeader.uncompressedPageSize
    override def compressedPageSize: Int = _underlying_PageHeader.compressedPageSize
    override def crc: _root_.scala.Option[Int] = _underlying_PageHeader.crc
    override def dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader] = _underlying_PageHeader.dataPageHeader
    override def dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader] = _underlying_PageHeader.dictionaryPageHeader
    override def dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2] = _underlying_PageHeader.dataPageHeaderV2
    override def _passthroughFields = _underlying_PageHeader._passthroughFields
  }
}

/**
 * Prefer the companion object's [[parquet.format.PageHeader.apply]]
 * for construction if you don't need to specify passthrough fields.
 */
trait PageHeader
  extends ThriftStruct
  with _root_.scala.Product7[parquet.format.PageType, Int, Int, Option[Int], Option[parquet.format.DataPageHeader], Option[parquet.format.DictionaryPageHeader], Option[parquet.format.DataPageHeaderV2]]
  with HasThriftStructCodec3[PageHeader]
  with java.io.Serializable
{
  import PageHeader._

  def `type`: parquet.format.PageType
  def uncompressedPageSize: Int
  def compressedPageSize: Int
  def crc: _root_.scala.Option[Int]
  def dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader]
  def dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader]
  def dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2]

  def _passthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty

  def _1 = `type`
  def _2 = uncompressedPageSize
  def _3 = compressedPageSize
  def _4 = crc
  def _5 = dataPageHeader
  def _6 = dictionaryPageHeader
  def _7 = dataPageHeaderV2

  def toTuple: _root_.scala.Tuple7[parquet.format.PageType, Int, Int, Option[Int], Option[parquet.format.DataPageHeader], Option[parquet.format.DictionaryPageHeader], Option[parquet.format.DataPageHeaderV2]] = {
    (
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crc,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2
    )
  }


  /**
   * Gets a field value encoded as a binary blob using TCompactProtocol.  If the specified field
   * is present in the passthrough map, that value is returned.  Otherwise, if the specified field
   * is known and not optional and set to None, then the field is serialized and returned.
   */
  def getFieldBlob(_fieldId: Short): _root_.scala.Option[TFieldBlob] = {
    lazy val _buff = new TMemoryBuffer(32)
    lazy val _oprot = new TCompactProtocol(_buff)
    _passthroughFields.get(_fieldId) match {
      case blob: _root_.scala.Some[TFieldBlob] => blob
      case _root_.scala.None => {
        val _fieldOpt: _root_.scala.Option[TField] =
          _fieldId match {
            case 1 =>
              if (`type` ne null) {
                writeTypeValue(`type`, _oprot)
                _root_.scala.Some(PageHeader.TypeField)
              } else {
                _root_.scala.None
              }
            case 2 =>
              if (true) {
                writeUncompressedPageSizeValue(uncompressedPageSize, _oprot)
                _root_.scala.Some(PageHeader.UncompressedPageSizeField)
              } else {
                _root_.scala.None
              }
            case 3 =>
              if (true) {
                writeCompressedPageSizeValue(compressedPageSize, _oprot)
                _root_.scala.Some(PageHeader.CompressedPageSizeField)
              } else {
                _root_.scala.None
              }
            case 4 =>
              if (crc.isDefined) {
                writeCrcValue(crc.get, _oprot)
                _root_.scala.Some(PageHeader.CrcField)
              } else {
                _root_.scala.None
              }
            case 5 =>
              if (dataPageHeader.isDefined) {
                writeDataPageHeaderValue(dataPageHeader.get, _oprot)
                _root_.scala.Some(PageHeader.DataPageHeaderField)
              } else {
                _root_.scala.None
              }
            case 6 =>
              if (dictionaryPageHeader.isDefined) {
                writeDictionaryPageHeaderValue(dictionaryPageHeader.get, _oprot)
                _root_.scala.Some(PageHeader.DictionaryPageHeaderField)
              } else {
                _root_.scala.None
              }
            case 7 =>
              if (dataPageHeaderV2.isDefined) {
                writeDataPageHeaderV2Value(dataPageHeaderV2.get, _oprot)
                _root_.scala.Some(PageHeader.DataPageHeaderV2Field)
              } else {
                _root_.scala.None
              }
            case _ => _root_.scala.None
          }
        _fieldOpt match {
          case _root_.scala.Some(_field) =>
            _root_.scala.Some(TFieldBlob(_field, Buf.ByteArray.Owned(_buff.getArray())))
          case _root_.scala.None =>
            _root_.scala.None
        }
      }
    }
  }

  /**
   * Collects TCompactProtocol-encoded field values according to `getFieldBlob` into a map.
   */
  def getFieldBlobs(ids: TraversableOnce[Short]): immutable$Map[Short, TFieldBlob] =
    (ids flatMap { id => getFieldBlob(id) map { id -> _ } }).toMap

  /**
   * Sets a field using a TCompactProtocol-encoded binary blob.  If the field is a known
   * field, the blob is decoded and the field is set to the decoded value.  If the field
   * is unknown and passthrough fields are enabled, then the blob will be stored in
   * _passthroughFields.
   */
  def setField(_blob: TFieldBlob): PageHeader = {
    var `type`: parquet.format.PageType = this.`type`
    var uncompressedPageSize: Int = this.uncompressedPageSize
    var compressedPageSize: Int = this.compressedPageSize
    var crc: _root_.scala.Option[Int] = this.crc
    var dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader] = this.dataPageHeader
    var dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader] = this.dictionaryPageHeader
    var dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2] = this.dataPageHeaderV2
    var _passthroughFields = this._passthroughFields
    _blob.id match {
      case 1 =>
        `type` = readTypeValue(_blob.read)
      case 2 =>
        uncompressedPageSize = readUncompressedPageSizeValue(_blob.read)
      case 3 =>
        compressedPageSize = readCompressedPageSizeValue(_blob.read)
      case 4 =>
        crc = _root_.scala.Some(readCrcValue(_blob.read))
      case 5 =>
        dataPageHeader = _root_.scala.Some(readDataPageHeaderValue(_blob.read))
      case 6 =>
        dictionaryPageHeader = _root_.scala.Some(readDictionaryPageHeaderValue(_blob.read))
      case 7 =>
        dataPageHeaderV2 = _root_.scala.Some(readDataPageHeaderV2Value(_blob.read))
      case _ => _passthroughFields += (_blob.id -> _blob)
    }
    new Immutable(
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crc,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2,
      _passthroughFields
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetField(_fieldId: Short): PageHeader = {
    var `type`: parquet.format.PageType = this.`type`
    var uncompressedPageSize: Int = this.uncompressedPageSize
    var compressedPageSize: Int = this.compressedPageSize
    var crc: _root_.scala.Option[Int] = this.crc
    var dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader] = this.dataPageHeader
    var dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader] = this.dictionaryPageHeader
    var dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2] = this.dataPageHeaderV2

    _fieldId match {
      case 1 =>
        `type` = null
      case 2 =>
        uncompressedPageSize = 0
      case 3 =>
        compressedPageSize = 0
      case 4 =>
        crc = _root_.scala.None
      case 5 =>
        dataPageHeader = _root_.scala.None
      case 6 =>
        dictionaryPageHeader = _root_.scala.None
      case 7 =>
        dataPageHeaderV2 = _root_.scala.None
      case _ =>
    }
    new Immutable(
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crc,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2,
      _passthroughFields - _fieldId
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetType: PageHeader = unsetField(1)

  def unsetUncompressedPageSize: PageHeader = unsetField(2)

  def unsetCompressedPageSize: PageHeader = unsetField(3)

  def unsetCrc: PageHeader = unsetField(4)

  def unsetDataPageHeader: PageHeader = unsetField(5)

  def unsetDictionaryPageHeader: PageHeader = unsetField(6)

  def unsetDataPageHeaderV2: PageHeader = unsetField(7)


  override def write(_oprot: TProtocol): Unit = {
    PageHeader.validate(this)
    _oprot.writeStructBegin(Struct)
    if (`type` ne null) writeTypeField(`type`, _oprot)
    writeUncompressedPageSizeField(uncompressedPageSize, _oprot)
    writeCompressedPageSizeField(compressedPageSize, _oprot)
    if (crc.isDefined) writeCrcField(crc.get, _oprot)
    if (dataPageHeader.isDefined) writeDataPageHeaderField(dataPageHeader.get, _oprot)
    if (dictionaryPageHeader.isDefined) writeDictionaryPageHeaderField(dictionaryPageHeader.get, _oprot)
    if (dataPageHeaderV2.isDefined) writeDataPageHeaderV2Field(dataPageHeaderV2.get, _oprot)
    if (_passthroughFields.nonEmpty) {
      _passthroughFields.values.foreach { _.write(_oprot) }
    }
    _oprot.writeFieldStop()
    _oprot.writeStructEnd()
  }

  def copy(
    `type`: parquet.format.PageType = this.`type`,
    uncompressedPageSize: Int = this.uncompressedPageSize,
    compressedPageSize: Int = this.compressedPageSize,
    crc: _root_.scala.Option[Int] = this.crc,
    dataPageHeader: _root_.scala.Option[parquet.format.DataPageHeader] = this.dataPageHeader,
    dictionaryPageHeader: _root_.scala.Option[parquet.format.DictionaryPageHeader] = this.dictionaryPageHeader,
    dataPageHeaderV2: _root_.scala.Option[parquet.format.DataPageHeaderV2] = this.dataPageHeaderV2,
    _passthroughFields: immutable$Map[Short, TFieldBlob] = this._passthroughFields
  ): PageHeader =
    new Immutable(
      `type`,
      uncompressedPageSize,
      compressedPageSize,
      crc,
      dataPageHeader,
      dictionaryPageHeader,
      dataPageHeaderV2,
      _passthroughFields
    )

  override def canEqual(other: Any): Boolean = other.isInstanceOf[PageHeader]

  private def _equals(x: PageHeader, y: PageHeader): Boolean =
      x.productArity == y.productArity &&
      x.productIterator.sameElements(y.productIterator)

  override def equals(other: Any): Boolean =
    canEqual(other) &&
      _equals(this, other.asInstanceOf[PageHeader]) &&
      _passthroughFields == other.asInstanceOf[PageHeader]._passthroughFields

  override def hashCode: Int = _root_.scala.runtime.ScalaRunTime._hashCode(this)

  override def toString: String = _root_.scala.runtime.ScalaRunTime._toString(this)


  override def productArity: Int = 7

  override def productElement(n: Int): Any = n match {
    case 0 => this.`type`
    case 1 => this.uncompressedPageSize
    case 2 => this.compressedPageSize
    case 3 => this.crc
    case 4 => this.dataPageHeader
    case 5 => this.dictionaryPageHeader
    case 6 => this.dataPageHeaderV2
    case _ => throw new IndexOutOfBoundsException(n.toString)
  }

  override def productPrefix: String = "PageHeader"

  def _codec: ThriftStructCodec3[PageHeader] = PageHeader
}

